{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint,shuffle\n",
    "from glob import glob\n",
    "\n",
    "import sys \n",
    "sys.path.append(os.path.join(os.path.expanduser(\"~\"),'station2grid'))\n",
    "from tools import CustomKNN,plotMap\n",
    "\n",
    "home=os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid2code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "domain,k,weights='air',5,'distance'\n",
    "single='domain_air-k_5-weightKNN_distance'\n",
    "grid_paths=glob(os.path.join(home,'station2grid','datasets','npy',domain,single,'grid','*'))\n",
    "grid_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_paths,test_paths=train_test_split(grid_paths,test_size=0.2, random_state=42)\n",
    "len(grid_paths),len(train_paths),len(test_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "norm_const=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generator_autoencoder(grid_paths,batch_size=2):\n",
    "    while True:\n",
    "        batch_x=[]\n",
    "        for i in range(batch_size):\n",
    "            j=randint(0,len(grid_paths)-1)\n",
    "            path=grid_paths[i]\n",
    "            one_dt = np.load(path)\n",
    "            one_dt_pm25 = one_dt[...,:1]\n",
    "            one_dt_pm25_norm = one_dt_pm25 / norm_const\n",
    "            one_dt_pm25_norm = one_dt_pm25_norm.astype('float')\n",
    "            batch_x.append(one_dt_pm25_norm)\n",
    "        batch_x=np.concatenate(batch_x,axis=0)\n",
    "        yield batch_x,batch_x\n",
    "\n",
    "        \n",
    "g_train=generator_autoencoder(train_paths,batch_size=2)\n",
    "batch_x,batch_y=next(g_train)\n",
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (348, 204, 1)\n",
    "input_img = Input(shape=input_shape)  \n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(4, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "\n",
    "# autoencoder\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "\n",
    "dir_path=os.path.join(home,'station2grid','weights','single',single,'grid2code','test')\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "\n",
    "\n",
    "file_name=\"g2c-epoch_{epoch:02d}-val_loss_{val_loss:.3f}.hdf5\"\n",
    "path=os.path.join(dir_path,file_name)\n",
    "checkpointer = ModelCheckpoint(filepath=path, verbose=1, monitor='val_loss', save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "g_train=generator_autoencoder(train_paths,batch_size=batch_size)\n",
    "g_test=generator_autoencoder(test_paths,batch_size=batch_size)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = autoencoder.fit_generator(\n",
    "    generator = g_train,\n",
    "    steps_per_epoch = (len(train_paths) // batch_size),\n",
    "    \n",
    "    validation_data = g_test,\n",
    "    validation_steps = (len(test_paths) // batch_size),\n",
    "    \n",
    "    epochs = epochs,\n",
    "    verbose = 1,\n",
    "    callbacks=[early_stopping,checkpointer],\n",
    "    \n",
    "    use_multiprocessing = True,\n",
    "    workers = 8,\n",
    "    max_queue_size = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('autoencoder', fontsize=30)\n",
    "plt.ylabel('cross entropy', fontsize=20)\n",
    "plt.xlabel('epoch', fontsize=20)\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=os.path.join(dir_path,'grid2code*')\n",
    "path_list = glob(path)\n",
    "path_list.sort()\n",
    "path=path_list[-1]\n",
    "print(path)\n",
    "\n",
    "# autoencoder\n",
    "autoencoder_best = load_model(path)\n",
    "autoencoder_best.summary()\n",
    "autoencoder_best.layers[6]\n",
    "\n",
    "# encoder\n",
    "encoder_best = Model(autoencoder_best.input, autoencoder_best.layers[6].output)\n",
    "encoder_best.summary()\n",
    "\n",
    "# decoder\n",
    "input_decoder = Input(shape=(44, 26, 4))\n",
    "x = autoencoder_best.layers[-7](input_decoder) \n",
    "x = autoencoder_best.layers[-6](x) \n",
    "x = autoencoder_best.layers[-5](x) \n",
    "x = autoencoder_best.layers[-4](x) \n",
    "x = autoencoder_best.layers[-3](x) \n",
    "x = autoencoder_best.layers[-2](x) \n",
    "output_decoder = autoencoder_best.layers[-1](x) \n",
    "decoder_best = Model(input_decoder, output_decoder)\n",
    "decoder_best.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = grid_paths[2]\n",
    "print(path)\n",
    "one_dt = np.load(path)\n",
    "one_dt_pm25 = one_dt[:,:,:,-1:]\n",
    "one_dt_pm25_norm = one_dt_pm25 / norm_const\n",
    "one_dt_pm25_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encode_path = path.replace('_grid','_encode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "one_ts_grid_pm25_norm_encode = encoder_best.predict(one_ts_grid_pm25_norm)\n",
    "one_ts_grid_pm25_norm_encode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint,shuffle\n",
    "from glob import glob\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,BatchNormalization,Activation\n",
    "from keras.models import Model,load_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "home=os.path.expanduser(\"~\")\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Grid2Code():\n",
    "    def __init__(self,opt):\n",
    "        self.opt=opt\n",
    "        self.single='domain_%s-k_%s-weightKNN_%s'%(opt.domain,opt.k,opt.weightKNN)\n",
    "        self.batch_size=opt.batch_size\n",
    "        self.domain=opt.domain\n",
    "        self.n_epochs = opt.n_epochs\n",
    "        self.autoencoderArcht=opt.autoencoderArcht\n",
    "        \n",
    "        self.grid_paths=self.get_paths()\n",
    "        self.trainPaths,self.valPaths=train_test_split(self.grid_paths,test_size=0.2, random_state=42)\n",
    "        self.autoencoder=self.get_autoencoder()\n",
    "        self.weight_dir=self.get_weight_dir()\n",
    "        \n",
    "    def get_autoencoder(self):\n",
    "        input_shape = (348, 204, 1)\n",
    "        input_img = Input(shape=input_shape)  \n",
    "\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(4, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        # autoencoder\n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "        \n",
    "        autoencoder.summary()\n",
    "        return autoencoder\n",
    "    \n",
    "    def train(self): \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, min_delta=0.01)\n",
    "        checkpointer=self.get_checkpointer()\n",
    "        \n",
    "        g_train=self.get_generator(self.trainPaths)\n",
    "        g_val=self.get_generator(self.valPaths)\n",
    "        \n",
    "        print('training...')\n",
    "        history = self.autoencoder.fit_generator(\n",
    "            generator = g_train,\n",
    "            steps_per_epoch = (len(self.trainPaths) // self.batch_size),\n",
    "\n",
    "            validation_data = g_val,\n",
    "            validation_steps = (len(self.valPaths) // self.batch_size),\n",
    "\n",
    "            epochs = self.n_epochs,\n",
    "            verbose = 0,\n",
    "            callbacks=[early_stopping,checkpointer],\n",
    "\n",
    "            use_multiprocessing = True,\n",
    "            workers = 8,\n",
    "            max_queue_size = 10,\n",
    "        )\n",
    "        print('finish!')\n",
    "        \n",
    "        df_history=pd.DataFrame(history.history)\n",
    "        path=os.path.join(self.weight_dir,'history.csv',)\n",
    "        df_history.to_csv(path,index=False)\n",
    "        \n",
    "    def test(self): \n",
    "        path=os.path.join(self.weight_dir,'grid2code*')\n",
    "        weights = glob(path)\n",
    "        weights.sort()\n",
    "        weight=weights[-1]\n",
    "        \n",
    "        print('testing...')\n",
    "        autoencoder_best = load_model(weight)\n",
    "        encoder_best = Model(autoencoder_best.input, autoencoder_best.layers[6].output)\n",
    "        \n",
    "        code_dir = self.grid_paths[0].split('/')[:-2]\n",
    "        code_dir=os.path.join('/'.join(code_dir),'code',self.autoencoderArcht)\n",
    "#         print(code_dir)\n",
    "        os.makedirs(code_dir,exist_ok=True)\n",
    "        \n",
    "        for grid_path in self.grid_paths[:]:\n",
    "            one_dt_pm25_norm=self.gridPath2arr(grid_path)\n",
    "            one_dt_pm25_norm_encode = encoder_best.predict(one_dt_pm25_norm)\n",
    "            encode_path=os.path.join(code_dir,grid_path.split('/')[-1].replace('grid','code'))\n",
    "#             print(encode_path)\n",
    "            np.save(encode_path,one_dt_pm25_norm_encode)\n",
    "\n",
    "        print('finish!')\n",
    "        \n",
    "    def get_paths(self):\n",
    "        grid_paths=glob(os.path.join(home,'station2grid','datasets','npy',self.domain,self.single,'grid','*'))\n",
    "        return grid_paths\n",
    "    \n",
    "    def gridPath2arr(self,path):\n",
    "        one_dt = np.load(path)\n",
    "        one_dt_pm25 = one_dt[...,:1]\n",
    "        one_dt_pm25_norm = self.normalize(one_dt_pm25)\n",
    "        return one_dt_pm25_norm\n",
    "    \n",
    "    def normalize(self,one_dt_pm25):\n",
    "        norm_const=100\n",
    "        one_dt_pm25_norm = one_dt_pm25 / norm_const\n",
    "        one_dt_pm25_norm = one_dt_pm25_norm.astype('float')\n",
    "        return one_dt_pm25_norm\n",
    "    \n",
    "    def denormalize(self,arr):\n",
    "        norm_const=100\n",
    "        return arr*norm_const\n",
    "    \n",
    "    def get_generator(self,grid_paths):\n",
    "        while True:\n",
    "            batch_x=[]\n",
    "            for i in range(self.batch_size):\n",
    "                j=randint(0,len(grid_paths)-1)\n",
    "                grid_path=grid_paths[i]\n",
    "                one_dt_pm25_norm=self.gridPath2arr(grid_path)\n",
    "                batch_x.append(one_dt_pm25_norm)\n",
    "            batch_x=np.concatenate(batch_x,axis=0)\n",
    "            yield batch_x,batch_x\n",
    "    \n",
    "    def get_weight_dir(self):\n",
    "        weight_dir=os.path.join(home,'station2grid','weights','single',self.single,'grid2code',self.autoencoderArcht)\n",
    "        os.makedirs(weight_dir,exist_ok=True)\n",
    "        return weight_dir\n",
    "    \n",
    "    def get_checkpointer(self):\n",
    "        file_name=\"grid2code-epoch_{epoch:02d}-val_loss_{val_loss:.3f}.hdf5\"\n",
    "        path=os.path.join(self.weight_dir,file_name)\n",
    "        checkpointer = ModelCheckpoint(filepath=path, verbose=1, period=1,monitor='val_loss', save_best_only=True, mode='min')\n",
    "        return checkpointer\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.networks import AE\n",
    "from tools.data_generator import DataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "class Grid2Code():\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        self.ae = AE(opt)\n",
    "        self.dataGenerator = DataGenerator(opt)\n",
    "        self.setup_weight_dir()\n",
    "    \n",
    "    def train(self):\n",
    "        print('training...')\n",
    "        dataGenerator = self.dataGenerator\n",
    "        g_train = dataGenerator.generator_train\n",
    "        g_valid = dataGenerator.generator_valid\n",
    "        \n",
    "        self.autoencoder = self.ae.define_ae()\n",
    "        \n",
    "        callbacks = self.ae.get_callbacks(self.weight_dir)\n",
    "        \n",
    "        history = self.autoencoder.fit_generator(\n",
    "            generator = g_train,\n",
    "            steps_per_epoch = (len(dataGenerator.x_train_paths) // self.opt.batch_size),\n",
    "\n",
    "            validation_data = g_valid,\n",
    "            validation_steps = (len(dataGenerator.x_valid_paths) // self.opt.batch_size),\n",
    "\n",
    "            epochs = self.opt.n_epochs,\n",
    "            verbose = 0,\n",
    "            callbacks = callbacks,\n",
    "\n",
    "            use_multiprocessing = True,\n",
    "            workers = 8,\n",
    "            max_queue_size = 10,\n",
    "        )\n",
    "        \n",
    "        self.save_history(history)\n",
    "        print('finish!')\n",
    "        \n",
    "    def test(self): \n",
    "        print('testing...')\n",
    "        dataGenerator = self.dataGenerator\n",
    "        weights = sorted(glob(os.path.join(self.weight_dir, '*hdf5')))\n",
    "        weight = weights[-1]\n",
    "        \n",
    "        encoder_best = self.ae.get_encoder(weight)\n",
    "        \n",
    "        code_dir = os.path.join(dataGenerator.base_dir, 'code', self.opt.ae_type)\n",
    "        os.makedirs(code_dir, exist_ok=True)\n",
    "        \n",
    "        grid_paths = dataGenerator.get_paths('grid')\n",
    "        for grid_path in grid_paths[:]:\n",
    "            grid = dataGenerator.grid_path2arr(grid_path)\n",
    "            code = encoder_best.predict(grid)\n",
    "            code_name = grid_path.split('/')[-1].replace('grid', 'code')\n",
    "            code_path = os.path.join(code_dir, code_name)\n",
    "            np.save(code_path, code)\n",
    "        print('finish!')\n",
    "        \n",
    "    \n",
    "    def save_history(self, history):\n",
    "        df_history = pd.DataFrame(history.history)\n",
    "        path = os.path.join(self.weight_dir, 'history.csv',)\n",
    "        df_history.to_csv(path, index=False)\n",
    "        \n",
    "    def setup_weight_dir(self):\n",
    "        opt = self.opt\n",
    "        source = 'domain_%s-k_%s-weightKNN_%s'%(opt.domain, opt.k, opt.weightKNN)\n",
    "        self.weight_dir = os.path.join(home, 'station2grid', 'weights', 'single', source, opt.model_name, opt.ae_type)\n",
    "        os.makedirs(self.weight_dir, exist_ok=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Opt():\n",
    "    def __init__(self, domain='air', k=5, weightKNN='distance', ae_type='A1', batch_size=2, n_epochs=10, model_name='grid2code', features='pm25_pm10', val_stations='Shilin_Guting'):\n",
    "        self.domain = domain\n",
    "        self.k = k\n",
    "        self.weightKNN = weightKNN\n",
    "        self.ae_type = ae_type\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model_name = model_name\n",
    "        self.features = features\n",
    "        self.val_stations = val_stations\n",
    "\n",
    "opt=Opt('air', 5, 'distance', 'A1', 2, 10, 'grid2code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid2code = Grid2Code(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid2code.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid2code.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# station2code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Station2Code():\n",
    "    def __init__(self,opt):\n",
    "        self.opt=opt\n",
    "        self.single='domain_%s-k_%s-weightKNN_%s'%(opt.domain,opt.k,opt.weightKNN)\n",
    "        self.batch_size=opt.batch_size\n",
    "        self.domain=opt.domain\n",
    "        self.n_epochs = opt.n_epochs\n",
    "        self.autoencoderArcht=opt.autoencoderArcht\n",
    "        ### \n",
    "        self.features=opt.features\n",
    "        self.valStations=opt.valStations\n",
    "        self.codeLength=opt.codeLength\n",
    "        self.domainFeatures=pd.read_csv(os.path.join(home,'station2grid','datasets','info','%s-features.csv'%(self.domain)))\n",
    "        self.epaStationInfo=pd.read_csv(os.path.join(home,'station2grid','datasets','info','epa-station-info.csv'))\n",
    "        self.n_features=len(self.features.split('_'))\n",
    "        self.n_valStations=len(self.valStations.split('_'))\n",
    "        self.iFeatures=[self.domainFeatures.feature.tolist().index(feature) for feature in self.features.split('_')]\n",
    "        self.iStations=self.epaStationInfo[~self.epaStationInfo.SiteEngName.isin(self.valStations.split('_'))].index.tolist()\n",
    "        \n",
    "        self.station_paths=self.get_paths('station')\n",
    "        self.trainPaths,self.valPaths=train_test_split(self.station_paths,test_size=0.2, random_state=42)\n",
    "        self.fnn=self.get_fnn()\n",
    "        self.weight_dir=self.get_weight_dir()\n",
    "        \n",
    "    def get_fnn(self):\n",
    "        num_station = 73-self.n_valStations\n",
    "        num_encoded = self.codeLength #4576\n",
    "        input_ = Input(shape=(num_station,self.n_features))\n",
    "        x = Flatten()(input_)\n",
    "        x = Dense(500, activation='relu')(x)\n",
    "        x = Dense(2500, activation='relu')(x)\n",
    "        output_ = Dense(num_encoded, activation='linear')(x)\n",
    "        model = Model(input_, output_)\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def train(self): \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3) # , min_delta=0.01\n",
    "        checkpointer=self.get_checkpointer()\n",
    "        \n",
    "        g_train=self.get_generator(self.trainPaths)\n",
    "        g_val=self.get_generator(self.valPaths)\n",
    "        \n",
    "        print('training...')\n",
    "        history = self.fnn.fit_generator(\n",
    "            generator = g_train,\n",
    "            steps_per_epoch = (len(self.trainPaths) // self.batch_size),\n",
    "\n",
    "            validation_data = g_val,\n",
    "            validation_steps = (len(self.valPaths) // self.batch_size),\n",
    "\n",
    "            epochs = self.n_epochs,\n",
    "            verbose = 0,\n",
    "            callbacks=[early_stopping,checkpointer],\n",
    "\n",
    "            use_multiprocessing = True,\n",
    "            workers = 8,\n",
    "            max_queue_size = 10,\n",
    "        )\n",
    "        print('finish!')\n",
    "        \n",
    "        df_history=pd.DataFrame(history.history)\n",
    "        path=os.path.join(self.weight_dir,'history.csv',)\n",
    "        df_history.to_csv(path,index=False)\n",
    "    \n",
    "    def get_generator(self,station_paths):\n",
    "        while True:\n",
    "            batch_x=[]\n",
    "            batch_y=[]\n",
    "            for i in range(self.batch_size):\n",
    "                j=randint(0,len(station_paths)-1)\n",
    "                ### x\n",
    "                station_path=station_paths[i]\n",
    "                one_dt_station=self.stationPath2arr(station_path)\n",
    "                batch_x.append(one_dt_station)\n",
    "                ### y\n",
    "                code_path=self.stationPath2codePath(station_path)\n",
    "                one_dt_code=self.codePath2arr(code_path)\n",
    "                batch_y.append(one_dt_code)\n",
    "                \n",
    "            batch_x=np.concatenate(batch_x,axis=0)\n",
    "            batch_y=np.concatenate(batch_y,axis=0)\n",
    "            yield batch_x,batch_y\n",
    "    \n",
    "        \n",
    "    def get_paths(self,fileType):\n",
    "        if fileType in ['station','grid']:\n",
    "            paths=glob(os.path.join(home,'station2grid','datasets','npy',self.domain,self.single,fileType,'*'))\n",
    "        else:\n",
    "            paths=glob(os.path.join(home,'station2grid','datasets','npy',self.domain,self.single,self.autoencoderArcht,fileType,'*'))\n",
    "        return paths\n",
    "    \n",
    "    def stationPath2codePath(self,stationPath):\n",
    "        code_path=stationPath.split('/')\n",
    "        code_path=os.path.join('/'.join(code_path[:-2]),'code',self.autoencoderArcht,code_path[-1].replace('station','code'))\n",
    "        return code_path       \n",
    "    \n",
    "    def stationPath2arr(self,path):\n",
    "        one_dt = np.load(path)\n",
    "        one_dt_pm25 = one_dt[:,self.iStations,:][...,self.iFeatures]\n",
    "        one_dt_pm25_norm = self.normalize(one_dt_pm25)\n",
    "        return one_dt_pm25_norm\n",
    "    \n",
    "    def codePath2arr(self,path):\n",
    "        one_dt=np.load(path)\n",
    "        one_dt=one_dt.reshape(1,-1)\n",
    "        return one_dt\n",
    "    \n",
    "    def normalize(self,one_dt_pm25):\n",
    "        norm_const=100\n",
    "        one_dt_pm25_norm = one_dt_pm25 / norm_const\n",
    "        one_dt_pm25_norm = one_dt_pm25_norm.astype('float')\n",
    "        return one_dt_pm25_norm\n",
    "    \n",
    "    def get_weight_dir(self):\n",
    "        weight_dir=os.path.join(home,'station2grid','weights','single',self.single,'station2code',self.autoencoderArcht,str(self.n_valStations),self.valStations,self.features)\n",
    "        os.makedirs(weight_dir,exist_ok=True)\n",
    "        return weight_dir\n",
    "    \n",
    "    def get_checkpointer(self):\n",
    "        file_name=\"station2code-epoch_{epoch:02d}-val_loss_{val_loss:.3f}.hdf5\"\n",
    "        path=os.path.join(self.weight_dir,file_name)\n",
    "        checkpointer = ModelCheckpoint(filepath=path, verbose=1, period=1,monitor='val_loss', save_best_only=True, mode='min')\n",
    "        return checkpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.networks import AE, FCNN\n",
    "from tools.data_generator import DataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "class Station2Code():\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        self.fcnn = FCNN(opt)\n",
    "        self.dataGenerator = DataGenerator(opt)\n",
    "        \n",
    "        self.n_val_stations = len(self.opt.val_stations.split('_')) ###\n",
    "        self.n_features = len(self.opt.features.split('_')) ###\n",
    "        self.setup_weight_dir()\n",
    "    \n",
    "    def train(self):\n",
    "        print('training...')\n",
    "        dataGenerator = self.dataGenerator\n",
    "        g_train = dataGenerator.generator_train\n",
    "        g_valid = dataGenerator.generator_valid\n",
    "        \n",
    "        self.s2c_model = self.fcnn.define_fcnn(self.n_val_stations, self.n_features, self.opt.code_length)\n",
    "        \n",
    "        callbacks = self.s2c_model.get_callbacks(self.weight_dir)\n",
    "        \n",
    "        history = self.s2c_model.fit_generator(\n",
    "            generator = g_train,\n",
    "            steps_per_epoch = (len(dataGenerator.x_train_paths) // self.opt.batch_size),\n",
    "\n",
    "            validation_data = g_valid,\n",
    "            validation_steps = (len(dataGenerator.x_valid_paths) // self.opt.batch_size),\n",
    "\n",
    "            epochs = self.opt.n_epochs,\n",
    "            verbose = 0,\n",
    "            callbacks = callbacks,\n",
    "\n",
    "            use_multiprocessing = True,\n",
    "            workers = 8,\n",
    "            max_queue_size = 10,\n",
    "        )\n",
    "        \n",
    "        self.save_history(history)\n",
    "        print('finish!')\n",
    "        \n",
    "    \n",
    "    def save_history(self, history):\n",
    "        df_history = pd.DataFrame(history.history)\n",
    "        path = os.path.join(self.weight_dir, 'history.csv',)\n",
    "        df_history.to_csv(path, index=False)\n",
    "        \n",
    "    def setup_weight_dir(self):\n",
    "        opt = self.opt\n",
    "        source = 'domain_%s-k_%s-weightKNN_%s'%(opt.domain, opt.k, opt.weightKNN)\n",
    "        self.weight_dir = os.path.join(home, 'station2grid', 'weights', 'single', source, opt.model_name, opt.ae_type, str(self.n_val_stations), opt.val_stations, opt.features)\n",
    "        os.makedirs(self.weight_dir, exist_ok=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Opt():\n",
    "    def __init__(self, domain='air', k=5, weightKNN='distance', ae_type='A1', batch_size=2, n_epochs=10, model_name='grid2code', features='pm25_pm10', val_stations='Shilin_Guting', code_length=4576):\n",
    "        self.domain = domain\n",
    "        self.k = k\n",
    "        self.weightKNN = weightKNN\n",
    "        self.ae_type = ae_type\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model_name = model_name\n",
    "        self.features = features\n",
    "        self.val_stations = val_stations\n",
    "        self.code_length = code_length\n",
    "        \n",
    "opt=Opt('air', 5, 'distance', 'A1', 2, 10, 'station2code', features='pm25_temperature_pm10_humidity', val_stations='Chaozhou_Shilin_Guting_Puli', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "station2code=Station2Code(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station2code.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station2GridSingle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Station2GridSingle():\n",
    "    def __init__(self,opt):\n",
    "        self.single='domain_%s-k_%s-weightKNN_%s'%(opt.domain,opt.k,opt.weightKNN)\n",
    "        self.domain=opt.domain\n",
    "        self.autoencoderArcht=opt.autoencoderArcht\n",
    "        ### \n",
    "        self.features=opt.features\n",
    "        self.valStations=opt.valStations\n",
    "        self.codeLength=opt.codeLength\n",
    "        self.stationFeatures=pd.read_csv(os.path.join(home,'station2grid','datasets','info','epa-features.csv'))\n",
    "        self.epaStationInfo=pd.read_csv(os.path.join(home,'station2grid','datasets','info','epa-station-info.csv'))\n",
    "        self.n_features=len(self.features.split('_'))\n",
    "        self.n_valStations=len(self.valStations.split('_'))\n",
    "        self.iFeatures=[self.stationFeatures.feature.tolist().index(feature) for feature in self.features.split('_')]\n",
    "        self.iStations=self.epaStationInfo[~self.epaStationInfo.SiteEngName.isin(self.valStations.split('_'))].index.tolist()\n",
    "        \n",
    "        ###\n",
    "        self.stationPath=opt.stationPath\n",
    "    \n",
    "\n",
    "    def get_decoder(self):\n",
    "        weight=self.get_weight('grid2code')\n",
    "        # autoencoder\n",
    "        autoencoder_best = load_model(weight)\n",
    "        # decoder\n",
    "        input_decoder = Input(shape=(44, 26, 4))\n",
    "        x = autoencoder_best.layers[-7](input_decoder) \n",
    "        x = autoencoder_best.layers[-6](x) \n",
    "        x = autoencoder_best.layers[-5](x) \n",
    "        x = autoencoder_best.layers[-4](x) \n",
    "        x = autoencoder_best.layers[-3](x) \n",
    "        x = autoencoder_best.layers[-2](x) \n",
    "        output_decoder = autoencoder_best.layers[-1](x) \n",
    "        decoder_best = Model(input_decoder, output_decoder)\n",
    "        return decoder_best\n",
    "    \n",
    "    def get_fnn(self):\n",
    "        weight=self.get_weight('station2code')\n",
    "        nn_best = load_model(weight)\n",
    "        return nn_best\n",
    "    \n",
    "    def test(self): \n",
    "        print('load model') \n",
    "        print('########################################################')\n",
    "        fnn=self.get_fnn()\n",
    "        decoder=self.get_decoder()\n",
    "        print('########################################################')\n",
    "        print('processing...')\n",
    "        stations=self.stationPath2arr(self.stationPath)\n",
    "        \n",
    "        codes=fnn.predict(stations)\n",
    "        codes=codes.reshape(-1, 44, 26, 4)\n",
    "        \n",
    "        grids=decoder.predict(codes)\n",
    "        grids=self.denormalize(grids)\n",
    "        print('finish!')\n",
    "        return grids\n",
    "    \n",
    "    def stationPath2arr(self,path):\n",
    "        one_dt = np.load(path)\n",
    "        one_dt_pm25 = one_dt[:,self.iStations,:][...,self.iFeatures]\n",
    "        one_dt_pm25_norm = self.normalize(one_dt_pm25)\n",
    "        return one_dt_pm25_norm\n",
    "    \n",
    "    def normalize(self,one_dt_pm25):\n",
    "        norm_const=100\n",
    "        one_dt_pm25_norm = one_dt_pm25 / norm_const\n",
    "        one_dt_pm25_norm = one_dt_pm25_norm.astype('float')\n",
    "        return one_dt_pm25_norm\n",
    "    \n",
    "    def denormalize(self,arr):\n",
    "        norm_const=100\n",
    "        arr=norm_const*arr\n",
    "        arr = arr.astype('float')\n",
    "        return arr\n",
    "    \n",
    "    def get_weight(self,modelType):\n",
    "        base_dir=os.path.join(home,'station2grid','weights','single',self.single,modelType,self.autoencoderArcht)\n",
    "        if modelType=='grid2code':\n",
    "            weight_dir=os.path.join(base_dir,'*hdf5')\n",
    "        elif modelType=='station2code':\n",
    "            weight_dir=os.path.join(base_dir,str(self.n_valStations),self.valStations,self.features,'*hdf5')\n",
    "        weights=sorted(glob(weight_dir))\n",
    "        weight=weights[-1]\n",
    "        print(weight)\n",
    "        return weight\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.networks import AE, FCNN\n",
    "from tools.data_generator import DataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "class Station2GridSD():\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        self.ae = AE(opt)\n",
    "        self.fcnn = FCNN(opt)\n",
    "        self.dataGenerator = DataGenerator(opt)\n",
    "        \n",
    "        self.n_val_stations = len(self.opt.val_stations.split('_')) ###\n",
    "        self.n_features = len(self.opt.features.split('_')) ###\n",
    "        self.setup_weight_dir()\n",
    "    \n",
    "    def test(self): \n",
    "        print('testing...')\n",
    "        dataGenerator = self.dataGenerator\n",
    "        \n",
    "        g2c_weights = sorted(glob(os.path.join(self.g2c_weight_dir, '*hdf5')))\n",
    "        g2c_weight = g2c_weights[-1]\n",
    "        s2c_weights = sorted(glob(os.path.join(self.s2c_weight_dir, '*hdf5')))\n",
    "        s2c_weight = s2c_weights[-1]\n",
    "\n",
    "        c2g_model = self.ae.get_decoder(g2c_weight)\n",
    "        s2c_model = self.fcnn.get_fcnn(s2c_weight)\n",
    "        \n",
    "        self.stations = dataGenerator.station_path2arr(self.opt.epa_station_path)\n",
    "        \n",
    "        codes=s2c_model.predict(self.stations)\n",
    "        codes=codes.reshape(-1, 44, 26, 4)\n",
    "        \n",
    "        grids=c2g_model.predict(codes)\n",
    "        grids=dataGenerator.denormalize(grids)\n",
    "        print('finish!')\n",
    "        return grids\n",
    "    \n",
    "    def save_history(self, history):\n",
    "        df_history = pd.DataFrame(history.history)\n",
    "        path = os.path.join(self.weight_dir, 'history.csv',)\n",
    "        df_history.to_csv(path, index=False)\n",
    "        \n",
    "    def setup_weight_dir(self):\n",
    "        opt = self.opt\n",
    "        source = 'domain_%s-k_%s-weightKNN_%s'%(opt.domain, opt.k, opt.weightKNN)\n",
    "        base_dir = os.path.join(home, 'station2grid', 'weights', 'single', source)\n",
    "        self.g2c_weight_dir = os.path.join(base_dir, 'grid2code', opt.ae_type)\n",
    "        self.s2c_weight_dir = os.path.join(base_dir, 'station2code', opt.ae_type, str(self.n_val_stations), opt.val_stations, opt.features)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Opt():\n",
    "    def __init__(self, domain='air', k=5, weightKNN='distance', ae_type='A1', batch_size=2, n_epochs=10, model_name='grid2code', features='pm25_pm10', val_stations='Shilin_Guting', code_length=4576, epa_station_path=''):\n",
    "        self.domain = domain\n",
    "        self.k = k\n",
    "        self.weightKNN = weightKNN\n",
    "        self.ae_type = ae_type\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model_name = model_name\n",
    "        self.features = features\n",
    "        self.val_stations = val_stations\n",
    "        self.code_length = code_length\n",
    "        self.epa_station_path = epa_station_path\n",
    "        \n",
    "epa_station_path = os.path.join(home, 'station2grid', 'datasets', 'npy', 'epa', 'epa2014.npy')\n",
    "opt=Opt('air', 5, 'distance', 'A1', 2, 10, model_name='station2gridSD', features='pm25_temperature_pm10_humidity', val_stations='Chaozhou_Shilin_Guting_Puli', epa_station_path=epa_station_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station2GridSD = Station2GridSD(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing...\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "grids = station2GridSD.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 348, 204, 1), (48, 69, 4))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids.shape,station2GridSD.stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# refactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(os.path.join(os.path.expanduser(\"~\"),'station2grid'))\n",
    "from tools import CustomKNN, plotMap, data_generator\n",
    "from tools.data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt():\n",
    "    def __init__(self, domain='air', k=5, weightKNN='distance', ae_type='A1', batch_size=2, n_epochs=10, model_name='grid2code', features='pm25_pm10', val_stations='Shilin_Guting'):\n",
    "        self.domain = domain\n",
    "        self.k = k\n",
    "        self.weightKNN = weightKNN\n",
    "        self.ae_type = ae_type\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model_name = model_name\n",
    "        self.features = features\n",
    "        self.val_stations = val_stations\n",
    "\n",
    "opt=Opt('air', 5, 'distance', 'A1', 2, 10, 'grid2code')\n",
    "dataGenerator = DataGenerator(opt)\n",
    "generator = dataGenerator.generator_valid\n",
    "batch_x, batch_y = next(generator)\n",
    "batch_x.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Opt('air', 5, 'distance', 'A1', 2, 10, 'station2code', features='pm25_temperature_pm10_humidity', val_stations='Chaozhou_Shilin_Guting_Puli')\n",
    "dataGenerator = DataGenerator(opt)\n",
    "generator = dataGenerator.generator\n",
    "batch_x, batch_y = next(generator)\n",
    "batch_x.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.networks import Autoencoder, FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt():\n",
    "    def __init__(self, domain='air', k=5, weightKNN='distance', ae_type='A1', batch_size=2, n_epochs=10, model_name='grid2code', features='pm25_pm10', val_stations='Shilin_Guting'):\n",
    "        self.domain = domain\n",
    "        self.k = k\n",
    "        self.weightKNN = weightKNN\n",
    "        self.ae_type = ae_type\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model_name = model_name\n",
    "        self.features = features\n",
    "        self.val_stations = val_stations\n",
    "\n",
    "opt=Opt('air', 5, 'distance', 'A1', 2, 10, 'grid2code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder=Autoencoder(opt).define_autoencoder()\n",
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn=FCNN(opt).define_fcnn(5,3,4576)\n",
    "# fcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
